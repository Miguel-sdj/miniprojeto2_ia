{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNXZxI-_cNgK"
   },
   "source": [
    "# Problema 1 - Geração de Texto com RNNs ou Transformers\n",
    "## Descrição: Crie um gerador de texto para um propósito específico (por exemplo, poesias, histórias curtas ou trechos de código).\n",
    "\n",
    "### Objetivos:\n",
    "\n",
    "- Implementar um modelo RNN, LSTM ou Transformer para a geração de texto.\n",
    "- Treinar o modelo em um conjunto de dados de escolha, como poemas, literatura clássica ou um conjunto de dados de\n",
    "programação.\n",
    "\n",
    "### Grupo:\n",
    "- Miguel Cabral de Carvalho\n",
    "- Luiz Fernando Paes de Barros Presta\n",
    "- Ana Clara Didier\n",
    "- Pedro Dantas Leite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKM_55pYcx64"
   },
   "source": [
    "# Coleta de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47QWsi7WcLx4",
    "outputId": "9db36d8e-4227-413d-bb8b-82d1357ccf9f"
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "\n",
    "# def get_poems():\n",
    "#     # URL da seção \"Animals\"\n",
    "#     url = \"https://www.poetryfoundation.org/poems/browse/animals\"\n",
    "\n",
    "#     # Requisição HTTP\n",
    "#     response = requests.get(url)\n",
    "#     poems = []\n",
    "\n",
    "#     if response.status_code == 200:\n",
    "#         # Parsear o conteúdo da página\n",
    "#         soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "#         # Buscar todos os links dos poemas\n",
    "#         links = soup.find_all(\"a\", class_=\"link-underline-on link-red\")\n",
    "\n",
    "#         for link in links:\n",
    "#             poem_url = \"https://www.poetryfoundation.org\" + link.get(\"href\")\n",
    "#             poem_response = requests.get(poem_url)\n",
    "\n",
    "#             if poem_response.status_code == 200:\n",
    "#                 poem_soup = BeautifulSoup(poem_response.content, \"html.parser\")\n",
    "#                 poem_content = poem_soup.find(\"div\", class_=\"poem-body\")\n",
    "\n",
    "#                 if poem_content:\n",
    "#                     # Remover caracteres desnecessários e tags HTML\n",
    "#                     poem_text = poem_content.get_text(strip=True)\n",
    "#                     poem_text = re.sub(r'\\s+', ' ', poem_text)  # Substituir múltiplos espaços por um único\n",
    "#                     poems.append(poem_text)\n",
    "\n",
    "#     return poems\n",
    "\n",
    "# poems = get_poems()\n",
    "\n",
    "# print(f\"Quantidade de poemas encontrados: {len(poems)}\")\n",
    "\n",
    "# if poems:\n",
    "#     print(\"Primeiro poema encontrado:\")\n",
    "#     print(poems[0][:500])  # Imprime os primeiros 500 caracteres do primeiro poema encontrado\n",
    "# else:\n",
    "#     print(\"Nenhum poema encontrado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _multiarray_umath: Não foi possível encontrar o módulo especificado.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: Não foi possível encontrar o módulo especificado."
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _multiarray_umath: Não foi possível encontrar o módulo especificado.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: Não foi possível encontrar o módulo especificado."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Title  \\\n",
      "77  At Eighty-three She Lives Alone   \n",
      "6              And the Gauchos Sing   \n",
      "29                from Saying Grace   \n",
      "78             Leaving the Hospital   \n",
      "13                            Relic   \n",
      "\n",
      "                                                 Poem               Poet  \\\n",
      "77  Enclosure, steam-heated; a trial casket.You ar...         Ruth Stone   \n",
      "6   For Barry SileskyCatalpas blooming up and down...        Mike Puican   \n",
      "29  for my motherthe living     1.After Independen...        Kevin Young   \n",
      "78  As the doors glide shut behind me, the world f...        Anya Silver   \n",
      "13  The first time I touched it, cloth fell under ...  Rachel Richardson   \n",
      "\n",
      "                                                 Tags  \n",
      "77                 Living,Growing Old,Arts & Sciences  \n",
      "6   Arts & Sciences,Poetry & Poets,Social Commenta...  \n",
      "29  Activities,Jobs & Working,Social Commentaries,...  \n",
      "78                                            No Tags  \n",
      "13                                            No Tags  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\migue\\AppData\\Local\\Temp\\ipykernel_6588\\172790358.py:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  data = data.applymap(lambda x: x.strip().replace(\"\\r\", \"\").replace(\"\\n\", \"\") if isinstance(x, str) else x)\n",
      "C:\\Users\\migue\\AppData\\Local\\Temp\\ipykernel_6588\\172790358.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Tags'].fillna('No Tags', inplace=True)\n",
      "C:\\Users\\migue\\AppData\\Local\\Temp\\ipykernel_6588\\172790358.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Poem'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"PoetryFoundationData.csv\"\n",
    "\n",
    "data_completa = pd.read_csv(file_path, index_col=0)\n",
    "data = data_completa.sample(frac=0.03, random_state=42)\n",
    "\n",
    "data = data.applymap(lambda x: x.strip().replace(\"\\r\", \"\").replace(\"\\n\", \"\") if isinstance(x, str) else x)\n",
    "data['Tags'].fillna('No Tags', inplace=True)\n",
    "data['Poem'].fillna('', inplace=True)\n",
    "\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irJ92rnrissE"
   },
   "source": [
    "# Pré processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7UYh8RAirX0",
    "outputId": "1ac5cdab-5877-4dff-a40e-3dd49c96b708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeiras palavras dos poemas:\n",
      "['enclosure', 'steamheated', 'a', 'trial', 'casket', 'you', 'are', 'here', 'your', 'name']\n",
      "\n",
      "Número total de tokens: 18347\n",
      "Exemplo de sequência X[0]: [3240 5342    3 5343 3241   11   25  107   36  211   15    3 5344  362\n",
      " 1882   53  198  160   17 5345   40   38  401   11   40   38 2382    5\n",
      "   11   26    4   37 5346  992   61   37 5347 5348    1  345   37 5349\n",
      "   25  636 5350  139   11   74    1 5351]\n",
      "Exemplo de sequência y[0]: 266\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(poems):\n",
    "    text = ' '.join(poems)\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:]', '', text) \n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "poems = data['Poem'].tolist()\n",
    "cleaned_text = preprocess_text(poems)\n",
    "\n",
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts([cleaned_text]) # Tokenizar o texto\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences([cleaned_text])[0] # Converter o texto para sequência de tokens\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = {index: word for word, index in word_index.items()}\n",
    "\n",
    "print(\"\\nPrimeiras palavras dos poemas:\")\n",
    "first_10_words = [reverse_word_index[token] for token in sequences[:10]]\n",
    "print(first_10_words)\n",
    "\n",
    "seq_length = 50 \n",
    "input_sequences = []\n",
    "\n",
    "for i in range(seq_length, len(sequences)):\n",
    "    input_sequences.append(sequences[i-seq_length:i+1]) \n",
    "\n",
    "input_sequences = np.array(input_sequences)\n",
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "X = pad_sequences(X, maxlen=seq_length, padding='pre')\n",
    "\n",
    "print(f\"\\nNúmero total de tokens: {len(tokenizer.word_index)}\")\n",
    "print(f\"Exemplo de sequência X[0]: {X[0]}\")\n",
    "print(f\"Exemplo de sequência y[0]: {y[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKa2eTY8jQEc"
   },
   "source": [
    "# Modelo LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponível\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.test.is_built_with_cuda()\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU disponível\")\n",
    "\n",
    "else:\n",
    "    print(\"GPU não detectada\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "7O4bsvU5jSIH",
    "outputId": "b4b2f97a-6797-4be1-a8ab-b5b7fff520c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 50, 100)           1834800   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50, 512)           1255424   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 512)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 512)               2099200   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 18348)             9412524   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,601,948\n",
      "Trainable params: 14,601,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "1340/1340 [==============================] - 28s 17ms/step - loss: 7.6727 - accuracy: 0.0636\n",
      "Epoch 2/50\n",
      "1340/1340 [==============================] - 23s 17ms/step - loss: 7.3579 - accuracy: 0.0676\n",
      "Epoch 3/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 7.1820 - accuracy: 0.0711\n",
      "Epoch 4/50\n",
      "1340/1340 [==============================] - 23s 17ms/step - loss: 7.0139 - accuracy: 0.0726\n",
      "Epoch 5/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 6.8350 - accuracy: 0.0764\n",
      "Epoch 6/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 6.6557 - accuracy: 0.0854\n",
      "Epoch 7/50\n",
      "1340/1340 [==============================] - 23s 17ms/step - loss: 6.4306 - accuracy: 0.0928\n",
      "Epoch 8/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 6.1974 - accuracy: 0.0997\n",
      "Epoch 9/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 5.9473 - accuracy: 0.1068\n",
      "Epoch 10/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 5.6889 - accuracy: 0.1163\n",
      "Epoch 11/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 5.4107 - accuracy: 0.1241\n",
      "Epoch 12/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 5.1203 - accuracy: 0.1357\n",
      "Epoch 13/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 4.8249 - accuracy: 0.1517\n",
      "Epoch 14/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 4.5370 - accuracy: 0.1704\n",
      "Epoch 15/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 4.2721 - accuracy: 0.1945\n",
      "Epoch 16/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 4.0025 - accuracy: 0.2240\n",
      "Epoch 17/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 3.7632 - accuracy: 0.2499\n",
      "Epoch 18/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 3.5338 - accuracy: 0.2799\n",
      "Epoch 19/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 3.3304 - accuracy: 0.3074\n",
      "Epoch 20/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 3.1377 - accuracy: 0.3361\n",
      "Epoch 21/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 2.9759 - accuracy: 0.3630\n",
      "Epoch 22/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 2.8172 - accuracy: 0.3874\n",
      "Epoch 23/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 2.6733 - accuracy: 0.4104\n",
      "Epoch 24/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 2.5437 - accuracy: 0.4332\n",
      "Epoch 25/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 2.4130 - accuracy: 0.4547\n",
      "Epoch 26/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 2.3116 - accuracy: 0.4745\n",
      "Epoch 27/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 2.2068 - accuracy: 0.4916\n",
      "Epoch 28/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 2.1005 - accuracy: 0.5126\n",
      "Epoch 29/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 2.0087 - accuracy: 0.5271\n",
      "Epoch 30/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 1.9173 - accuracy: 0.5447\n",
      "Epoch 31/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 1.8435 - accuracy: 0.5577\n",
      "Epoch 32/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.7640 - accuracy: 0.5756\n",
      "Epoch 33/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 1.6956 - accuracy: 0.5872\n",
      "Epoch 34/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.6244 - accuracy: 0.6024\n",
      "Epoch 35/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.5637 - accuracy: 0.6133\n",
      "Epoch 36/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.5005 - accuracy: 0.6259\n",
      "Epoch 37/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.4376 - accuracy: 0.6388\n",
      "Epoch 38/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.3898 - accuracy: 0.6487\n",
      "Epoch 39/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.3457 - accuracy: 0.6579\n",
      "Epoch 40/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.2872 - accuracy: 0.6713\n",
      "Epoch 41/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.2374 - accuracy: 0.6806\n",
      "Epoch 42/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.1938 - accuracy: 0.6901\n",
      "Epoch 43/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.1571 - accuracy: 0.6984\n",
      "Epoch 44/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.1164 - accuracy: 0.7088\n",
      "Epoch 45/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.0796 - accuracy: 0.7164\n",
      "Epoch 46/50\n",
      "1340/1340 [==============================] - 22s 16ms/step - loss: 1.0405 - accuracy: 0.7241\n",
      "Epoch 47/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 1.0039 - accuracy: 0.7326\n",
      "Epoch 48/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 0.9736 - accuracy: 0.7417\n",
      "Epoch 49/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 0.9479 - accuracy: 0.7465\n",
      "Epoch 50/50\n",
      "1340/1340 [==============================] - 22s 17ms/step - loss: 0.9202 - accuracy: 0.7510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26beb8762e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=seq_length))\n",
    "model.add(LSTM(512, return_sequences=True)) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(LSTM(512)) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X, y, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfGBCsFKjWna"
   },
   "source": [
    "# Gerar texto com o nosso modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iq3ch7ojjY0w",
    "outputId": "cf8a29e7-d2ff-45be-8081-ba67587c0dd1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def generate_text(model, tokenizer, seq_length, seed_text, num_words=100):\n",
    "    input_text = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    input_text = pad_sequences([input_text], maxlen=seq_length, padding='pre')[0]\n",
    "\n",
    "    output_text = seed_text\n",
    "    for _ in range(num_words):\n",
    "        input_sequence = np.array([input_text[-seq_length:]]) \n",
    "        pred = model.predict(input_sequence, verbose=0)\n",
    "        predicted_word_index = np.argmax(pred)\n",
    "        predicted_word = tokenizer.index_word.get(predicted_word_index, '')\n",
    "        output_text += ' ' + predicted_word\n",
    "        input_text = np.append(input_text, predicted_word_index)\n",
    "        input_text = input_text[-seq_length:]\n",
    "\n",
    "    return output_text\n",
    "\n",
    "def get_user_input():\n",
    "    seed_text = input(\"Digite o texto inicial para gerar o poema: \")\n",
    "    num_words = int(input(\"Quantas palavras você deseja gerar? \"))\n",
    "    return seed_text, num_words\n",
    "\n",
    "seed_text, num_words = get_user_input()\n",
    "\n",
    "generated_text = generate_text(model, tokenizer, seq_length=50, seed_text=seed_text, num_words=num_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poema gerado:\n",
      "life there is a word in the lexicon of love my\n",
      "\n",
      "Poema gerado traduzido:\n",
      "Vida há uma palavra no léxico do amor meu\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "traducao = translator.translate(generated_text, src='en', dest='pt')\n",
    "\n",
    "\n",
    "print(\"\\nPoema gerado:\")\n",
    "print(generated_text)\n",
    "\n",
    "print(\"\\nPoema gerado traduzido:\")\n",
    "print(traducao.text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
